<<<<<<< Updated upstream
<<<<<<< Updated upstream
table1_case_rate <- table1_case_rate %>% select(county, combined) %>% # note that i took the first occurence of dane, so the lower case rate
table1_case_rate %>% arrange(county,combined) %>% distinct(county)
table1_case_rate <- table1_case_rate %>% select(county, combined) %>% # note that i took the first occurence of dane, so the lower case rate
table1_case_rate %>% arrange(county,combined) %>% distinct(county) %>% pull()
table1_case_rate <- table1_case_rate %>% select(county, combined) %>% # note that i took the first occurence of dane, so the lower case rate
table1_case_rate %>% arrange(county,combined)
table1_case_rate
table1_case_rate <- table1_case_rate %>% select(county, combined) %>% # note that i took the first occurence of dane, so the lower case rate
table1_case_rate %>% arrange(county)
table1_case_rate <- table1_case_rate %>% select(county, combined) %>% # note that i took the first occurence of dane, so the lower case rate
table1_case_rate %>% arrange(desc(county))
table1_case_rate <- table1_case_rate %>% select(county, combined) #%>% # note that i took the first occurence of dane, so the lower case rate
table1_case_rate %>% arrange(desc(county))
table1_case_rate %>% arrange(county, desc(combined))
table1_case_rate %>% arrange(county, desc(combined)) %>% distinct(county)
table1_case_rate %>% arrange(county, desc(combined)) %>% distinct(county,.keep_all=TRUE)
table1_case_rate
table1_case_rate <- table1_case_rate %>% select(county, combined) #%>% # note that i took the first occurence of dane, so the higher case rate
table1_case_rate %>% arrange(county, desc(combined)) %>% distinct(county,.keep_all=TRUE)
table1_case_rate
table1 <- table1_names %>% left_join(table1_gender, by = "county") %>% left_join(table1_age, by = "county") %>% left_join(table1_price_index, by = "county") %>% left_join(table1_case_rate, by = "county") #%>% select(County = name, mask_usage, c, y, a, e, range, combined ) #%>% mutate(combined = round(combined, 2))
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
table1
table1_names <- merged %>% group_by(county) %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>%
=======
rownames(x) = x[,1]
y = x[,-1]
x = y
View(x)
colSums(x)
hist(x)
x
x[,1]
x[,2]
x[,3]
x[,4]
hist(matrix(x))
hist(as.matrix(x))
density(as.matrix(x))
plot(density(as.matrix(x)))
plot(density(as.matrix(log10(x))))
plot(density(as.matrix(log10(colSums(x)))))
plot(density(as.matrix(colSums(x))))
plot((as.matrix(colSums(x)))
boxplot(as.matrix(colSums(x)))))
boxplot(as.matrix(colSums(x))))
boxplot(as.matrix(colSums(x)))
boxplot(as.matrix(colSums(log2(x)))
boxplot(as.matrix(colSums(log2(x))))
boxplot(as.matrix(log2(colSums(x))))
colnames(x)
cor(x)
source("https://bioconductor.org/biocLite.R")
install.packages("BiocManager")
BiocManager::install()
as.dist(cor(x))
d = as.dist(cor(x))
View(d)
pheatmap(cor(x))
library(pheatmap)
BiocManager::install("pheatmap")
library(pheatmap)
pheatmap(cor(x))
x[,c(1,2)]
x[,c(1,2)]
colSums(x[,c(1,2)])
plot(x[,c(1,2)])
plot(log2(x[,c(1,2)]))
density(x[,c(1)])
plot(density(x[,c(1)]))
x[,c(1)]
sum(x[,c(1)]>1)
BiocManager::install(c("pheatmap","edgeR"))
library(pheatmap); library(edgeR)
pheatmap(cor(cpm(x,log=T)))
plot(cpm(x[,c(1,2)],log=T))
x
plot(cpm(x[,c(1,"DNAX.Neg.7.27.17")],log=T))
plot(cpm(x[,c("X623","DNAX.Neg.7.27.17")],log=T))
plot(cpm(x[,c("X623","DNAX.Neg.7.27.17")],log=F))
ls
write(colnames(x),file="/Volumes/DATA/Tung-Warrior_VitB/names.txt")
knitr::opts_chunk$set(echo = TRUE)
less(count_matrix)
page(count_matrix_DE)
library(data.table)
count_matrix = fread("WarriorFinal.final.abund.opti_mcc.unique_list.0.03.norm.shared",data.table=F)
count_matrix = count_matrix[order(count_matrix$Group),]
tmp = t(count_matrix[,-(c(1:3))])
colnames(tmp) = count_matrix$Group
count_matrix_DE = as.data.frame(tmp)
page(count_matrix_DE)
tmp = t(count_matrix[,-(c(1:3))])
colnames(tmp) = count_matrix$Group
count_matrix_DE = as.data.frame(tmp)
head(count_matrix_DE)
count_matrix_DE_filtered = count_matrix_DE[rowSums(count_matrix_DE)!=0,]
dim(count_matrix_DE_filtered)
count_matrix_DE_filtered = count_matrix_DE[rowSums(count_matrix_DE)==0,]
dim(count_matrix_DE_filtered)
count_matrix_DE_filtered = count_matrix_DE[rowSums(count_matrix_DE)>5,]
dim(count_matrix_DE_filtered)
count_matrix_DE_filtered = count_matrix_DE[rowSums(count_matrix_DE)>10,]
dim(count_matrix_DE_filtered)
abline(h=1)
barplot(log10(rowSums(count_matrix_DE)))
abline(h=1)
abline(h=1,col="red")
barplot(log10(rowSums(count_matrix_DE)))
abline(h=1,col="red")
cmdf = count_matrix_DE_filtered
cor(cmdf)
pheatmap(cor(cmdf))
library(pheatmap)
pheatmap(cor(cmdf))
colSums(cmdf)
plot(colSums(cmdf))
library(pheatmap)
pheatmap(cor(cmdf,method="pearson"))
pheatmap(cor(cmdf,method="spearman"))
lcdmf = cpm(cdmf,log=T)
library(edgeR)
lcdmf = cpm(cdmf,log=T)
lcdmf = cpm(cmdf,log=T)
lcmdf = cpm(cmdf,log=T)
lcmdf
colSums(lcmdf)
pheatmap(cor(cmdf,method="spearman"))
pheatmap(cor(lcmdf,method="spearman"))
pheatmap(cor(lcmdf,method="pearson"))
pheatmap(cor(lcmdf,method="spearman"))
cmdf
cor(t(cmdf))
cor(t(cmdf[1:700],))
cor(t(cmdf[1:700,]))
pheatmap(cor(t(cmdf[1:200,])))
pheatmap(cor(t(cmdf[1:800,])))
pheatmap(abs(cor(t(cmdf[1:800,]))))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="spearman")))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")),annotation_col=rowSums(cmdf))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")),annotation_col=rowSums(cmdf[1:1000,]))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")),annotation_col=data.frame(Counts=rowSums(cmdf[1:1000,])))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")),annotation_col=data.frame(Counts=log10(rowSums(cmdf[1:1000,]))))
View(cor(cmdf)
View(cor(cmdf))
cor(cmdf)
cor(cmdf)
#cor(cmdf)
#looks like sample 2 and 13
View(cmdf)
plot(cmdf[colnames(cmdf)%in%c(2,3)])
plot(cmdf[colnames(cmdf)%in%c(2,13)])
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]))
nrow(cmdf)
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]))
contour(log2(cmdf[colnames(cmdf)%in%c(2,13)]))
ggplot(cmdf) +
geom_hex() +
theme_bw()
library(ggplot2)
#BiocManager::install(c("edgeR", "limma","data.table"))
BiocManager::install(c("edgeR", "limma","data.table","ggplot2"))
ggplot(cmdf) +
geom_hex() +
theme_bw()
library(ggplot2)
ggplot(cmdf) +
geom_hex() +
theme_bw()
ggplot(cmdf,aes(colnames(cmdf)%in%c(2,13)])) +
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]))
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 125, names = "blue50"))
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
length(count_matrix_DE)
apply(count_matrix_DE,1,sum)
apply(count_matrix_DE,1,x>5)
apply(count_matrix_DE,1,>5)
apply(count_matrix_DE,1,function(x){x>5})
cmdf2 = count_matrix_DE
cmdf2 = cmdf2[apply(cmdf2, 1, FUN = function(x) sum(x>= 5)>=2),]
cmdf2 = cmdf2[apply(cmdf2, 1, FUN = function(x) sum(x>= 5)>=40),]
dim(cmdf2)
cmdf2 = cmdf2[apply(cmdf2, 1, FUN = function(x) sum(x>= 5)>=20),]
dim(cmdf2)
cmdf2 = count_matrix_DE
cmdf2 = cmdf2[apply(cmdf2, 1, FUN = function(x) sum(x>= 5)>=20),]
dim(cmdf2)
plot(log2(cmdf2[colnames(cmdf2)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
pheatmap(cor(cmdf2,method="pearson"))
pheatmap(cor(cmdf,method="pearson"))
pheatmap(cor(cmdf2,method="spearman"))
pheatmap(abs(cor(cmdf2,method="spearman")))
pheatmap(abs(cor(cmdf2,method="pearson")))
plot(cmdf2[colnames(cmdf2)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50")
plot(cmdf2[colnames(cmdf2)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(cmdf2[colnames(cmdf2)%in%c(2,13)],col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(log10(cmdf2[colnames(cmdf2)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(log10(cmdf2[colnames(cmdf2)%in%c(2,1)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(log10(cmdf2[colnames(cmdf2)%in%c(2,100)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(log10(cmdf2[colnames(cmdf2)%in%c(2,1)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
library(BiocManager)
BiocManager::install("rtweet")
library(rtweet)
jkr <- get_favorites("jk_rowling", n = 3000)
jkr <- get_favorites("jk_rowling", n = 3000)
jkr
class(jkr)
jkr[[1]]
jkr[[2]]
jkr[[3]]
jkr[[4]]
library(BiocManager)
BiocManager::install("rtweet")
jkr
jkr <- get_favorites("jk_rowling", n = 3000)
library(rtweet)
jkr <- get_favorites("jk_rowling", n = 3000)
jkr
jkr$text
?get_favorites
jkr$geo_coords
jkr$place_name
jkr$account_created_at
jkr$geo_coords
jkr$geo_coords
jkr$retweet_location
jkr$place_url
jkr$country
jkr$coords_coords
jkr$place_name
jkr$place_full_name
power.t.test
4**5
4^5
wp.logistic
install.packages()
install.packages("WebPower")
wp.logistic
library(WebPower)
wp.logistic
pwr.f2.test
install.packages("pwr")
library(pwr)
pwr.f2.test
### Install packages only if not present
if (!require("ggpubr")) install.packages("ggpubr")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("forestplot")) install.packages("forestplot")
if (!require("ggmap")) install.packages("ggmap")
if (!require("maps")) install.packages("maps")
if (!require("mapdata")) install.packages("mapdata")
### Loading packages
library(ggpubr); library(tidyverse); library(forestplot)
### Setting working directory for Github repo
setwd('~/Documents/GitHub/ProjectSnafu')
# SECTION 1: Generate Price Index AND combine into observation table ####
ppe_meta = read.csv("InputData/ppe_meta_data.csv - CURRENT - ppe_meta_data.csv - Sheet1.csv", stringsAsFactors = FALSE)
ppe_meta = ppe_meta %>% filter(type=="grocery")
str(ppe_meta)
ppe_meta$price_of_good = as.numeric(ppe_meta$price_of_good)
AvgZscorePriceIndex = ppe_meta %>%
filter(!(name_of_good == "oranges")) %>%
group_by(name_of_good) %>%
mutate(zscore_price = (price_of_good-mean(price_of_good, na.rm = TRUE)) / sd(price_of_good, na.rm = TRUE)) %>%
group_by(id) %>%
summarize(avg_zscore_price_index = mean(zscore_price, na.rm = TRUE),
median_zscore_price_index = median(zscore_price, na.rm = TRUE)) %>%
left_join(ppe_meta, by = "id") %>%
select(id = id, county = county, name = name, type = type, location = location, avg_zscore_price_index, median_zscore_price_index, pop_density, pop_total, case_rate_june19, case_rate_two_weeks_prior) %>%
unique()
# Making combined file of ppe and avg price
small_PI_table = AvgZscorePriceIndex %>%
select(id, avg_zscore_price_index, median_zscore_price_index, pop_density, pop_total, case_rate_june19, case_rate_two_weeks_prior)
ppe_obs = read.csv("InputData/ppe_observation_data - CURRENT - ppe_observation_data - Sheet1.csv", stringsAsFactors = FALSE) %>%
filter(type=="grocery") %>%
left_join(small_PI_table, by = "id")
# Convert blank observations to zero
ppe_obs[is.na(ppe_obs)] = 0
merged = ppe_obs
merged$age = replace(merged$age, merged$age=="A", "a")
merged$age = replace(merged$age, merged$age=="E", "e")
merged$age = replace(merged$age, merged$age=="Y", "y")
merged$age = replace(merged$age, merged$age=="C", "c")
# Filter out rows with the non-standard typo notation of ages
merged = merged %>% filter(age %in% c("a","e","y","c"))
old_age_to_new_age_mapping = data.frame(age = c("a", "e", "y", "c", "t"),
age_two_bins = c("30+", "30+", "0-29", "0-29", "0-29")) # 2-bin age not used for analysis
merged = merged %>% left_join(old_age_to_new_age_mapping, by = "age")
hist(merged$avg_zscore_price_index)
write.csv(merged, "InputData/meta_merged_observed.csv")
# SECTION 2: Generate TABLE 1 ####
table1_names = merged %>% group_by(county) %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/", n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>%
>>>>>>> Stashed changes
unite(name, county:n, sep = ", n = ", remove = FALSE)
table1_names
table1_gender <- merged %>% group_by(county, gender) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = gender, values_from = mask_usage)
table1_gender
table1_age <- merged %>% group_by(county, age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage)
table1_age
table1_price_index <- merged %>% group_by(county) %>% summarize(max_PI = round(max(avg_zscore_price_index, na.rm = TRUE), 1), min_PI = round(min(avg_zscore_price_index, na.rm = TRUE), 1)) %>% unite(range, min_PI:max_PI, sep = "," )
table1_price_index
table1_case_rate <- merged %>% select(county, case_rate, no_cases) %>% unique() %>% filter(no_cases != 538) #%>% mutate(case_rate = round(case_rate, 2) #%>% paste0(case_rate, " (", no_cases, ")", collapse = "")
table1_case_rate
table1_case_rate$combined <- paste0(table1_case_rate$case_rate, " (", table1_case_rate$no_cases, ")")
table1_case_rate <- table1_case_rate %>% select(county, combined) #%>% # note that i took the first occurence of dane, so the higher case rate
table1_case_rate %>% arrange(county, desc(combined)) %>% distinct(county,.keep_all=TRUE)
table1_case_rate
table1_case_rate %>% arrange(county, desc(combined)) %>% distinct(county,.keep_all=TRUE)
table1_case_rate = table1_case_rate %>% arrange(county, desc(combined)) %>% distinct(county,.keep_all=TRUE)
table1_case_rate
table1 <- table1_names %>% left_join(table1_gender, by = "county") %>% left_join(table1_age, by = "county") %>% left_join(table1_price_index, by = "county") %>% left_join(table1_case_rate, by = "county") #%>% select(County = name, mask_usage, c, y, a, e, range, combined ) #%>% mutate(combined = round(combined, 2))
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
table1
View(merged)
merged %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = ""))
merged %>% summarize(n = n(),
mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = ""),
Female = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")
)
merged %>% group_by(gender) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = gender, values_from = mask_usage)
merged %>% group_by(county, age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage)
merged %>% group_by(age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage)
table1_case_rate
merged %>% select(county, case_rate, no_cases) %>% unique() %>% filter(no_cases != 538)
merged %>% select(county, case_rate, no_cases) %>% unique() %>% filter(no_cases != 538)
merged %>% select(case_rate, no_cases) %>% unique() %>% filter(no_cases != 538)
# Make a total column
cbind(merged %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")),
merged %>% group_by(gender) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = gender, values_from = mask_usage),
merged %>% group_by(age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage))
# Make a total column
cbind(merged %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")),
merged %>% group_by(gender) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = gender, values_from = mask_usage),
merged %>% group_by(age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage),
rep(0,2)
)
# Make a total column
cbind(merged %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")),
merged %>% group_by(gender) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = gender, values_from = mask_usage),
merged %>% group_by(age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage),
0,0
)
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
rbind(table1,total
# Make a total column
total = cbind(merged %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")),
merged %>% group_by(gender) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = gender, values_from = mask_usage),
merged %>% group_by(age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage),
0,0
)
# Make a total column
total = cbind(merged %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")),
merged %>% group_by(gender) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = gender, values_from = mask_usage),
merged %>% group_by(age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage),
0,0)
table1 <- table1_names %>% left_join(table1_gender, by = "county") %>% left_join(table1_age, by = "county") %>% left_join(table1_price_index, by = "county") %>% left_join(table1_case_rate, by = "county") #%>% select(County = name, mask_usage, c, y, a, e, range, combined ) #%>% mutate(combined = round(combined, 2))
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
rbind(table1,total)
ncol(total)
ncol(table1)
View(table1)
View(total)
# Make a total column
total = cbind("Wisconsin","Total",merged %>% summarize(n = n(), mask_usage = paste0(c(sum(mask),"/",n(), " (", round(sum(mask)/n()*100, 1), ")"), collapse = "")),
merged %>% group_by(gender) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = gender, values_from = mask_usage),
merged %>% group_by(age) %>% summarize(mask_usage = paste0(c(sum(mask), "/",n()," (", round(sum(mask)/n()*100, 1), ")"), collapse = "")) %>% pivot_wider(names_from = age, values_from = mask_usage),
0,0)
ncol(total)
table1 <- table1_names %>% left_join(table1_gender, by = "county") %>% left_join(table1_age, by = "county") %>% left_join(table1_price_index, by = "county") %>% left_join(table1_case_rate, by = "county") #%>% select(County = name, mask_usage, c, y, a, e, range, combined ) #%>% mutate(combined = round(combined, 2))
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
rbind(table1,total)
ncol(table1)
View(table1)
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
final_table1 = rbind(table1,total)
ncol(final_tabl1)
ncol(final_table1)
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
final_table1 = rbind(table1,total)
View(total)
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
final_table1 = bind_rows(table1,total)
View(final_table1)
colnames(total) = colnames(table1)
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
final_table1 = bind_rows(table1,total)
#colnames(table1) <- c("County", "Total", "Male", "Female", "<18", "18-29", "30-59", "60+", "Price Index", "Cases per 100k")
final_table1 = rbind(table1,total)
View(final_table1)
<<<<<<< Updated upstream
table1
write.csv(table1, "Demographics/table.csv",sep="\t")
write.table(table1, "Demographics/table.csv")
write.table(table1, "Demographics/table.csv",sep="\t")
write.table(table1, "Demographics/table.txt",sep="\t")
write.table(table1, "Demographics/table.txt",sep="\t",quotes=F)
write.table(table1, "Demographics/table.txt",sep="\t",quote=F)
?write.table
write.table(table1, "Demographics/table.txt",sep="\t",quote=F,row.names=F)
write.table(final_table1, "Demographics/table.txt",sep="\t",quote=F,row.names=F)
# Let's calculate some odds ratios ####
library(tidyverse)
#install.packages("ggpubr")
library(ggpubr)
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
str(merged)
write.csv(table1, "merged.csv")
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv(merged)
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("merged.csv")
merged
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("merged.csv",row.names = 1)
merged
read.csv
?read.csv
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("merged.csv",row.names = 1, as.is = T)
merged
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("merged.csv",row.names = 1, check.names = F)
merged
write.csv(merged, "merged.csv")
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("merged.csv",row.names = 1, check.names = F)
str(merged)
head(merged)
write.csv(merged, "merged.csv")
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("merged.csv",row.names = 1, check.names = F)
head(merged)
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F)
head(merged)
head(merged)
str(merged)
merged$gender <- recode(merged$gender, `0` = "Male", `1` = "Female")
merged$age <- recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
merged$age <- fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age <- droplevels(merged$age)
print(dim(merged))
gender <- merged %>% group_by(gender) %>% summarize(`Percentage wearing face-coverings` = sum(mask, na.rm = TRUE)/n()*100) %>% ggplot(aes(x = as.factor(gender), y = `Percentage wearing face-coverings`)) + geom_bar(stat = "identity") + xlab(" ") + theme_bw()
age <- merged %>% group_by(age) %>% summarize(`Percentage wearing face-coverings` = sum(mask, na.rm = TRUE)/n()*100) %>% ggplot(aes(x = as.factor(age), y = `Percentage wearing face-coverings`)) + geom_bar(stat = "identity") + xlab(" ") + theme_bw()
#merged %>% ggplot(aes(x = workplaces_percent_change_from_baseline)) + geom_histogram()
gender
age
require(foreign)
require(ggplot2)
require(MASS)
require(Hmisc)
require(reshape2)
install.packages("Hmisc")
require(Hmisc)
require(reshape2)
m = polr(mask ~ age + gender + avg_zscore_price_index, data = merged, Hess=TRUE)
class(merged)
class(merged$mask)
class(merged$age)
class(merged$gender)
merged$gender <- as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F, stringsAsFactors = 1)
head(merged)
str(merged)
merged$gender <- as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
merged$age <- recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
merged$age <- fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age <- droplevels(merged$age)
print(dim(merged))
class(merged$gender)
class(merged$mask)
merged$mask = as.factor(merged$mask)
m = polr(mask ~ age + gender + avg_zscore_price_index, data = merged, Hess=TRUE)
summary(glm(location~gender + age +avg_zscore_price_index + case_rate, data = data))
summary(glm(location~gender + age +avg_zscore_price_index + case_rate, data = merged))
summary(glm(mask ~ gender + age +avg_zscore_price_index + case_rate, data = merged))
View(merged)
summary(glm(mask ~ gender  + avg_zscore_price_index + case_rate, data = merged))
summary(glm(mask ~ gender + case_rate, data = merged))
summary(glm(mask ~ gender, data = merged))
str(merged)
model = glm(mask ~ gender, data = merged)
model = glm(mask ~ gender, data = merged[,c("mask","gender")])
model = glm(gender ~ age, data = merged)
model = glm(gender ~ age, data = merged)
complete(merged$mask)
is.na(merged$mask)
sum(is.na(merged$mask))
model = glm(mask ~ age, data = merged)
merged
model = glm(mask ~ age, data = merged,family=binomial)
model
model = glm(mask ~ age + avg_zscore_price_index, data = merged,family=binomial)
summary(model)
model = glm(mask ~ age + avg_zscore_price_index + gender, data = merged,family=binomial)
summary(model)
model = glm(mask ~., data = merged, family=binomial)
model = glm(mask ~ age + avg_zscore_price_index + gender + date, data = merged, family=binomial)
summary(model)
exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95)))
?level
?as.factor()
str(merged)
model = glm(mask ~ age + avg_zscore_price_index + gender + date + no_cases, data = merged, family=binomial)
summary(model)
exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95)))
summary(model)
install.packages("meta")
library(meta)
library(meta)
install.packages("ggforestplot")
devtools::install_github("NightingaleHealth/ggforestplot")
library(devtools)
install.packages("devtools")
library(devtools)
devtools::install_github("NightingaleHealth/ggforestplot")
df_linear <-
ggforestplot::df_linear_associations %>%
dplyr::arrange(name) %>%
dplyr::filter(dplyr::row_number() <= 30)
df_linear
df_logodds <-
df_logodds_associations %>%
dplyr::arrange(name) %>%
dplyr::left_join(ggforestplot::df_NG_biomarker_metadata, by = "name") %>%
dplyr::filter(group == "Amino acids") %>%
# Set the study variable to a factor to preserve order of appearance
# Set class to factor to set order of display.
dplyr::mutate(
study = factor(
study,
levels = c("Meta-analysis", "NFBC-1997", "DILGOM", "FINRISK-1997", "YFS")
)
)
df_logodds <-
df_logodds_associations %>%
dplyr::arrange(name) %>%
dplyr::left_join(ggforestplot::df_NG_biomarker_metadata, by = "name") %>%
dplyr::filter(group == "Amino acids") %>%
# Set the study variable to a factor to preserve order of appearance
# Set class to factor to set order of display.
dplyr::mutate(
study = factor(
study,
levels = c("Meta-analysis", "NFBC-1997", "DILGOM", "FINRISK-1997", "YFS")
)
)
# Forestplot
forestplot(
df = df_logodds,
estimate = beta,
logodds = TRUE,
colour = study,
shape = study,
title = "Associations to type 2 diabetes",
xlab = "Odds ratio for incident type 2 diabetes (95% CI)
per 1−SD increment in metabolite concentration"
) +
# You may also want to add a manual shape scale to mark meta-analysis with a
# diamond shape
ggplot2::scale_shape_manual(
values = c(23L, 21L, 21L, 21L, 21L),
labels = c("Meta-analysis", "NFBC-1997", "DILGOM", "FINRISK-1997", "YFS")
)
library(ggforestplot)
# Forestplot
forestplot(
df = df_logodds,
estimate = beta,
logodds = TRUE,
colour = study,
shape = study,
title = "Associations to type 2 diabetes",
xlab = "Odds ratio for incident type 2 diabetes (95% CI)
per 1−SD increment in metabolite concentration"
) +
# You may also want to add a manual shape scale to mark meta-analysis with a
# diamond shape
ggplot2::scale_shape_manual(
values = c(23L, 21L, 21L, 21L, 21L),
labels = c("Meta-analysis", "NFBC-1997", "DILGOM", "FINRISK-1997", "YFS")
)
devtools::install_github("NightingaleHealth/ggforestplot", build_vignettes = TRUE)
devtools::install_github("NightingaleHealth/ggforestplot", build_vignettes = TRUE, force = TRUE)
library(ggforestplot)
# Forestplot
forestplot(
df = df_logodds,
estimate = beta,
logodds = TRUE,
colour = study,
shape = study,
title = "Associations to type 2 diabetes",
xlab = "Odds ratio for incident type 2 diabetes (95% CI)
per 1−SD increment in metabolite concentration"
) +
# You may also want to add a manual shape scale to mark meta-analysis with a
# diamond shape
ggplot2::scale_shape_manual(
values = c(23L, 21L, 21L, 21L, 21L),
labels = c("Meta-analysis", "NFBC-1997", "DILGOM", "FINRISK-1997", "YFS")
)
# Forestplot
forestplot(
df = df_logodds,
estimate = beta,
logodds = TRUE,
colour = study,
shape = study,
title = "Associations to type 2 diabetes",
xlab = "Odds ratio for incident type 2 diabetes (95% CI)
per 1−SD increment in metabolite concentration"
) +
# You may also want to add a manual shape scale to mark meta-analysis with a
# diamond shape
ggplot2::scale_shape_manual(
values = c(23L, 21L, 21L, 21L, 21L),
labels = c("Meta-analysis", "NFBC-1997", "DILGOM", "FINRISK-1997", "YFS")
)
install.packages("forestplot")
library(forestplot)
library(forestplot)
OR = exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95)))
OR = exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95)))
OR = exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95)))
OR
OR$`Odds ratio`
OR[,1
OR[,1]
class(OR)
OR = data.frame(exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95))))
class(OR)
OR[,1]
forest = structure(list(
mean = OR[,1],
lower = OR[,2],
upper = OR[,3]
))
forest
forest = structure(list(
mean = OR[,1],
lower = OR[,2],
upper = OR[,3],
.Names = c("mean", "lower", "upper"),
row.names = c(NA, -11L),
class = "data.frame")
))
forest = structure(list(
mean = OR[,1],
lower = OR[,2],
upper = OR[,3],
.Names = c("mean", "lower", "upper"),
row.names = c(NA, -11L),
class = "data.frame")
)
forest
# Cochrane data from the 'rmeta'-package
cochrane_from_rmeta <-
structure(list(
mean  = c(NA, NA, 0.578, 0.165, 0.246, 0.700, 0.348, 0.139, 1.017, NA, 0.531),
lower = c(NA, NA, 0.372, 0.018, 0.072, 0.333, 0.083, 0.016, 0.365, NA, 0.386),
upper = c(NA, NA, 0.898, 1.517, 0.833, 1.474, 1.455, 1.209, 2.831, NA, 0.731)),
.Names = c("mean", "lower", "upper"),
row.names = c(NA, -11L),
class = "data.frame")
forestplot(tabletext,
cochrane_from_rmeta)
?forestplot
# Let's calculate some odds ratios ####
library(tidyverse)
#install.packages("ggpubr")
library(ggpubr)
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F, stringsAsFactors = 1)
head(merged)
str(merged)
merged$gender <- as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"),)
merged$age <- recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
merged$age <- fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age <- droplevels(merged$age)
merged$gender <- as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
merged$age <- recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
merged$age <- fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age <- droplevels(merged$age)
=======
x = read.table("/Volumes/DATA/Tung-Warrior_VitB/denovo_unoise_otus/otutable.txt")
x = read.table("/Volumes/DATA/Tung-Warrior_VitB/denovo_unoise_otus/otutable.txt")
x
View(x)
x = read.table("/Volumes/DATA/Tung-Warrior_VitB/denovo_unoise_otus/otutable.txt",
header=T)
View(x)
colSums(x)
colSums(x)
x
typeof(x)
x[1]
class(x)
x[,1]
?read.table
x = read.table("/Volumes/DATA/Tung-Warrior_VitB/denovo_unoise_otus/otutable.txt",
header=T, stringsAsFactors=F)
colSums(x)
rownames(x) = x[,1]
x
x = read.table("/Volumes/DATA/Tung-Warrior_VitB/denovo_unoise_otus/otutable.txt",
header=T, stringsAsFactors=F)
rownames(x) = x[,1]
y = x[,-1]
x = y
View(x)
colSums(x)
hist(x)
x
x[,1]
x[,2]
x[,3]
x[,4]
hist(matrix(x))
hist(as.matrix(x))
density(as.matrix(x))
plot(density(as.matrix(x)))
plot(density(as.matrix(log10(x))))
plot(density(as.matrix(log10(colSums(x)))))
plot(density(as.matrix(colSums(x))))
plot((as.matrix(colSums(x)))
boxplot(as.matrix(colSums(x)))))
boxplot(as.matrix(colSums(x))))
boxplot(as.matrix(colSums(x)))
boxplot(as.matrix(colSums(log2(x)))
boxplot(as.matrix(colSums(log2(x))))
boxplot(as.matrix(log2(colSums(x))))
colnames(x)
cor(x)
source("https://bioconductor.org/biocLite.R")
install.packages("BiocManager")
BiocManager::install()
as.dist(cor(x))
d = as.dist(cor(x))
View(d)
pheatmap(cor(x))
library(pheatmap)
BiocManager::install("pheatmap")
library(pheatmap)
pheatmap(cor(x))
x[,c(1,2)]
x[,c(1,2)]
colSums(x[,c(1,2)])
plot(x[,c(1,2)])
plot(log2(x[,c(1,2)]))
density(x[,c(1)])
plot(density(x[,c(1)]))
x[,c(1)]
sum(x[,c(1)]>1)
BiocManager::install(c("pheatmap","edgeR"))
library(pheatmap); library(edgeR)
pheatmap(cor(cpm(x,log=T)))
plot(cpm(x[,c(1,2)],log=T))
x
plot(cpm(x[,c(1,"DNAX.Neg.7.27.17")],log=T))
plot(cpm(x[,c("X623","DNAX.Neg.7.27.17")],log=T))
plot(cpm(x[,c("X623","DNAX.Neg.7.27.17")],log=F))
ls
write(colnames(x),file="/Volumes/DATA/Tung-Warrior_VitB/names.txt")
knitr::opts_chunk$set(echo = TRUE)
less(count_matrix)
page(count_matrix_DE)
library(data.table)
count_matrix = fread("WarriorFinal.final.abund.opti_mcc.unique_list.0.03.norm.shared",data.table=F)
count_matrix = count_matrix[order(count_matrix$Group),]
tmp = t(count_matrix[,-(c(1:3))])
colnames(tmp) = count_matrix$Group
count_matrix_DE = as.data.frame(tmp)
page(count_matrix_DE)
tmp = t(count_matrix[,-(c(1:3))])
colnames(tmp) = count_matrix$Group
count_matrix_DE = as.data.frame(tmp)
head(count_matrix_DE)
count_matrix_DE_filtered = count_matrix_DE[rowSums(count_matrix_DE)!=0,]
dim(count_matrix_DE_filtered)
count_matrix_DE_filtered = count_matrix_DE[rowSums(count_matrix_DE)==0,]
dim(count_matrix_DE_filtered)
count_matrix_DE_filtered = count_matrix_DE[rowSums(count_matrix_DE)>5,]
dim(count_matrix_DE_filtered)
count_matrix_DE_filtered = count_matrix_DE[rowSums(count_matrix_DE)>10,]
dim(count_matrix_DE_filtered)
abline(h=1)
barplot(log10(rowSums(count_matrix_DE)))
abline(h=1)
abline(h=1,col="red")
barplot(log10(rowSums(count_matrix_DE)))
abline(h=1,col="red")
cmdf = count_matrix_DE_filtered
cor(cmdf)
pheatmap(cor(cmdf))
library(pheatmap)
pheatmap(cor(cmdf))
colSums(cmdf)
plot(colSums(cmdf))
library(pheatmap)
pheatmap(cor(cmdf,method="pearson"))
pheatmap(cor(cmdf,method="spearman"))
lcdmf = cpm(cdmf,log=T)
library(edgeR)
lcdmf = cpm(cdmf,log=T)
lcdmf = cpm(cmdf,log=T)
lcmdf = cpm(cmdf,log=T)
lcmdf
colSums(lcmdf)
pheatmap(cor(cmdf,method="spearman"))
pheatmap(cor(lcmdf,method="spearman"))
pheatmap(cor(lcmdf,method="pearson"))
pheatmap(cor(lcmdf,method="spearman"))
cmdf
cor(t(cmdf))
cor(t(cmdf[1:700],))
cor(t(cmdf[1:700,]))
pheatmap(cor(t(cmdf[1:200,])))
pheatmap(cor(t(cmdf[1:800,])))
pheatmap(abs(cor(t(cmdf[1:800,]))))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="spearman")))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")),annotation_col=rowSums(cmdf))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")),annotation_col=rowSums(cmdf[1:1000,]))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")),annotation_col=data.frame(Counts=rowSums(cmdf[1:1000,])))
pheatmap(abs(cor(t(cmdf[1:1000,]),method="pearson")),annotation_col=data.frame(Counts=log10(rowSums(cmdf[1:1000,]))))
View(cor(cmdf)
View(cor(cmdf))
cor(cmdf)
cor(cmdf)
#cor(cmdf)
#looks like sample 2 and 13
View(cmdf)
plot(cmdf[colnames(cmdf)%in%c(2,3)])
plot(cmdf[colnames(cmdf)%in%c(2,13)])
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]))
nrow(cmdf)
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]))
contour(log2(cmdf[colnames(cmdf)%in%c(2,13)]))
ggplot(cmdf) +
geom_hex() +
theme_bw()
library(ggplot2)
#BiocManager::install(c("edgeR", "limma","data.table"))
BiocManager::install(c("edgeR", "limma","data.table","ggplot2"))
ggplot(cmdf) +
geom_hex() +
theme_bw()
library(ggplot2)
ggplot(cmdf) +
geom_hex() +
theme_bw()
ggplot(cmdf,aes(colnames(cmdf)%in%c(2,13)])) +
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]))
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 125, names = "blue50"))
plot(log2(cmdf[colnames(cmdf)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
length(count_matrix_DE)
apply(count_matrix_DE,1,sum)
apply(count_matrix_DE,1,x>5)
apply(count_matrix_DE,1,>5)
apply(count_matrix_DE,1,function(x){x>5})
cmdf2 = count_matrix_DE
cmdf2 = cmdf2[apply(cmdf2, 1, FUN = function(x) sum(x>= 5)>=2),]
cmdf2 = cmdf2[apply(cmdf2, 1, FUN = function(x) sum(x>= 5)>=40),]
dim(cmdf2)
cmdf2 = cmdf2[apply(cmdf2, 1, FUN = function(x) sum(x>= 5)>=20),]
dim(cmdf2)
cmdf2 = count_matrix_DE
cmdf2 = cmdf2[apply(cmdf2, 1, FUN = function(x) sum(x>= 5)>=20),]
dim(cmdf2)
plot(log2(cmdf2[colnames(cmdf2)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
pheatmap(cor(cmdf2,method="pearson"))
pheatmap(cor(cmdf,method="pearson"))
pheatmap(cor(cmdf2,method="spearman"))
pheatmap(abs(cor(cmdf2,method="spearman")))
pheatmap(abs(cor(cmdf2,method="pearson")))
plot(cmdf2[colnames(cmdf2)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50")
plot(cmdf2[colnames(cmdf2)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(cmdf2[colnames(cmdf2)%in%c(2,13)],col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(log10(cmdf2[colnames(cmdf2)%in%c(2,13)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(log10(cmdf2[colnames(cmdf2)%in%c(2,1)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(log10(cmdf2[colnames(cmdf2)%in%c(2,100)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
plot(log10(cmdf2[colnames(cmdf2)%in%c(2,1)]),col=rgb(0, 0, 255, max = 255, alpha = 50, names = "blue50"))
library(BiocManager)
BiocManager::install("rtweet")
library(rtweet)
jkr <- get_favorites("jk_rowling", n = 3000)
jkr <- get_favorites("jk_rowling", n = 3000)
jkr
class(jkr)
jkr[[1]]
jkr[[2]]
jkr[[3]]
jkr[[4]]
library(BiocManager)
BiocManager::install("rtweet")
jkr
jkr <- get_favorites("jk_rowling", n = 3000)
library(rtweet)
jkr <- get_favorites("jk_rowling", n = 3000)
jkr
jkr$text
?get_favorites
jkr$geo_coords
jkr$place_name
jkr$account_created_at
jkr$geo_coords
jkr$geo_coords
jkr$retweet_location
jkr$place_url
jkr$country
jkr$coords_coords
jkr$place_name
jkr$place_full_name
power.t.test
4**5
4^5
wp.logistic
install.packages()
install.packages("WebPower")
wp.logistic
library(WebPower)
wp.logistic
pwr.f2.test
install.packages("pwr")
library(pwr)
pwr.f2.test
modelRR = glm(mask ~ age + gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log"), start=c(coefini,0,0,0))
=======
## Write out the Table 1 for Publication
write.table(final_table1, "Demographics/table.txt", sep="\t", quote=F, row.names=F)
>>>>>>> Stashed changes
# SECTION 3: Logistic Regression and Odds Ratios ####
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F, stringsAsFactors = 1)
merged$gender = as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
merged$gender = fct_relevel(merged$gender, ref = "Male")
#merged$age = recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
#merged$age = fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age = fct_relevel(merged$age, levels = c("c", "y", "a", "e"))
merged$age = droplevels(merged$age)
# Setting threshold for high case rate vs low case rate
threshold = 800
plot(density(merged$case_rate))
abline(v=threshold,col="red")
test = merged
#Grahing potential effect of interaction term
merged_top5_marker <- merged %>%
mutate(Top5 = case_when(
county %in% c("dane", "brown", "racine", "outagamie", "winnebago", "milwaukee", "kenosha") ~ "Top5",
TRUE ~ "Not top 5"))
merged_top5_marker %>%
group_by(county) %>%
summarize(percentage_wearing_mask = sum(mask)/n()*100) %>%
right_join(merged_top5_marker, by = "county") %>%
ggplot(aes(x = case_rate_two_weeks_prior, y = percentage_wearing_mask, color = pop_total, label = county)) +
facet_wrap(~Top5) +
geom_point() +
geom_smooth(method = lm, se = FALSE) +
scale_color_gradient(low = "grey", high = "blue", na.value = NA) +
geom_text(aes(label=county))
ggsave("./interaction_term_caserate_pop_total.png")
#top 5
# merged_top5 <- merged %>%
#   filter(county %in% c("dane", "brown", "racine", "outagamie", "winnebago"))
# merged_nottop5 <- merged %>%
#   filter(!(county %in% c("dane", "brown", "racine", "outagamie", "winnebago")))
model = glm(mask ~ age + avg_zscore_price_index + gender +case_rate*pop_total, data = merged, family = binomial)
summary(model)
# Converting logistic regression coef. into adjusted OR
OR = data.frame(exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95))), pvalue = summary(model)$coefficients[,4], check.names = F)
OR
# Remove the intercept row
abbreviated_1 = OR[-1,1]
abbreviated_2 = OR[-1,2]
abbreviated_3 = OR[-1,3]
abbreviated_4 = OR[-1,4]
# SECTION 4: Plot figure 1B for aOR ####
tabletext=cbind(
c(" ", "Young adult", "Adult", "Older adult", "High price index", "Female gender", "High case prevalence"),
c("aOR", formatC(abbreviated_1, digits = 2, drop0trailing = FALSE, format = "f")),
c("Lower CI", formatC(abbreviated_2, digits = 2, format = "f", drop0trailing = FALSE)),
c("Upper CI", formatC(abbreviated_3, digits = 2, format = "f", drop0trailing = FALSE)),
c("P-value", formatC(abbreviated_4, format = "e", digits = 2)))
### Install packages only if not present
if (!require("ggpubr")) install.packages("ggpubr")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("forestplot")) install.packages("forestplot")
if (!require("ggmap")) install.packages("ggmap")
if (!require("maps")) install.packages("maps")
if (!require("mapdata")) install.packages("mapdata")
# SECTION 3: Logistic Regression and Odds Ratios ####
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F, stringsAsFactors = 1)
merged$gender = as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
### Setting working directory for Github repo
setwd('~/Documents/GitHub/ProjectSnafu')
# SECTION 3: Logistic Regression and Odds Ratios ####
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F, stringsAsFactors = 1)
merged$gender = as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
merged$gender = fct_relevel(merged$gender, ref = "Male")
#merged$age = recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
#merged$age = fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age = fct_relevel(merged$age, levels = c("c", "y", "a", "e"))
merged$age = droplevels(merged$age)
>>>>>>> Stashed changes
print(dim(merged))
gender <- merged %>% group_by(gender) %>% summarize(`Percentage wearing face-coverings` = sum(mask, na.rm = TRUE)/n()*100) %>% ggplot(aes(x = as.factor(gender), y = `Percentage wearing face-coverings`)) + geom_bar(stat = "identity") + xlab(" ") + theme_bw()
View(merged)
merged
merged$mask = as.factor(merged$mask)
class(merged$mask)
sum(is.na(merged$mask))
model = glm(mask ~ age + avg_zscore_price_index + gender + date + no_cases, data = merged, family=binomial)
summary(model)
str(merged)
View(merged)
#View(merged)
#merged
OR = data.frame(exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95))))
OR
model = glm(mask ~ age + avg_zscore_price_index + gender + date + no_cases + weekend, data = merged, family=binomial)
model = glm(mask ~ age + avg_zscore_price_index + gender + date + no_cases + weekend, data = merged, family=binomial)
summary(model)
str(merged)
#View(merged)
#merged
OR = data.frame(exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95))))
OR
merged$weekend = as.factor(merged$weekend)
merged$mask = as.factor(merged$mask)
class(merged$mask)
sum(is.na(merged$mask))
model = glm(mask ~ age + avg_zscore_price_index + gender + date + no_cases + weekend, data = merged, family=binomial)
summary(model)
str(merged)
#View(merged)
#merged
OR = data.frame(exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95))))
OR
model = glm(mask ~ age + avg_zscore_price_index + gender + no_cases + weekend, data = merged, family=binomial)
summary(model)
str(merged)
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F, stringsAsFactors = 1)
head(merged)
str(merged)
merged$gender <- as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
merged = merged %>% filter(!name=="whl_fds")
head(merged)
merged$age <- recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
merged$age <- fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age <- droplevels(merged$age)
print(dim(merged))
merged$weekend = as.factor(merged$weekend)
#merged <- read.csv("/content/drive/Shared drives/MSTP 2019/Project - PPE/meta_merged_observed_mobility_race_income.csv") %>% filter(!(age %in% c("t", "0")), !(name %in% c("whl_fds", "metfalfes")), type == "grocery")
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F, stringsAsFactors = 1)
head(merged)
str(merged)
merged$gender <- as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
merged = merged %>% filter(!name=="whl_fds")
merged$age <- recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
merged$age <- fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age <- droplevels(merged$age)
print(dim(merged))
merged$weekend = as.factor(merged$weekend)
merged$mask = as.factor(merged$mask)
class(merged$mask)
sum(is.na(merged$mask))
model = glm(mask ~ age + avg_zscore_price_index + gender + no_cases + weekend, data = merged, family=binomial)
summary(model)
model = glm(mask ~ age + avg_zscore_price_index + gender + no_cases + weekend + location, data = merged, family=binomial)
summary(model)
str(merged)
#View(merged)
#merged
OR = data.frame(exp(cbind("Odds ratio" = coef(model), confint.default(model, level = 0.95))))
OR
<<<<<<< Updated upstream
model = glm(mask ~ no_cases, data = merged, family=binomial)
summary(model)
model = glm(mask ~ case_rate, data = merged, family=binomial)
summary(model)
model = glm(location ~ case_rate, data = merged, family=binomial)
summary(model)
exp(0.014520)
model = glm(mask ~ no_cases age + avg_zscore_price_index + gender + no_cases, data = merged, family=binomial)
summary(model)
model = glm(mask ~ no_cases age + avg_zscore_price_index + gender + no_cases, data = merged, family=binomial)
summary(model)
model = glm(mask ~ no_cases + age + avg_zscore_price_index + gender + no_cases, data = merged, family=binomial)
summary(model)
model = glm(mask ~ case_rate + age + avg_zscore_price_index + gender + no_cases, data = merged, family=binomial)
summary(model)
model = glm(mask ~ case_rate + age + avg_zscore_price_index + gender, data = merged, family=binomial)
summary(model)
plot(density(merged$case_rate))
plot(density(merged$no_cases))
plot(merged$avg_zscore_price_index,location)
plot(merged$avg_zscore_price_index,merged$location)
model = glm(location ~ AvgZscorePriceIndex, data = merged, family=binomial)
model = glm(location ~ avg_zscore_price_index, data = merged, family=binomial)
summary(model)
exp(.42)
=======
# Remove the intercept row
abbreviated_1 = OR[-1,1]
abbreviated_2 = OR[-1,2]
abbreviated_3 = OR[-1,3]
abbreviated_4 = OR[-1,4]
# SECTION 4: Plot figure 1B for aOR ####
tabletext=cbind(
c(" ", "Young adult", "Adult", "Older adult", "High price index", "Female gender", "High case prevalence"),
c("aOR", formatC(abbreviated_1, digits = 2, drop0trailing = FALSE, format = "f")),
c("Lower CI", formatC(abbreviated_2, digits = 2, format = "f", drop0trailing = FALSE)),
c("Upper CI", formatC(abbreviated_3, digits = 2, format = "f", drop0trailing = FALSE)),
c("P-value", formatC(abbreviated_4, format = "e", digits = 2)))
tabletext
forestplot(labeltext = tabletext,
mean = c(NA, abbreviated_1),
lower = c(NA, abbreviated_2),
upper = c(NA, abbreviated_3),
ci.vertices = T,
is.summary = c(TRUE, rep(FALSE, 7)),
fn.ci_norm = fpDrawCircleCI,
boxsize = 0.3,
txt_gp = fpTxtGp(ticks = gpar(cex = 3.6), xlab = gpar(cex = 3), label = gpar(cex =4)),
xlab = " ",
lwd.ci = 6,
xlog = TRUE,
#xticks = c(0, 1, 2, 3, 4, 5, 6),
hrzl_lines = gpar(col = "#444444"),
linesheight = "lines",
new_page = FALSE,
col = fpColors(box = c("black"), lines = "black"))
# SECTION 4: Plot figure 1B for aOR ####
tabletext=cbind(
c(" ", "Young adult", "Adult", "Older adult", "High price index", "Female gender", "High case prevalence"),
c("aOR", formatC(abbreviated_1, digits = 2, drop0trailing = FALSE, format = "f")),
c("Lower CI", formatC(abbreviated_2, digits = 2, format = "f", drop0trailing = FALSE)),
c("Upper CI", formatC(abbreviated_3, digits = 2, format = "f", drop0trailing = FALSE)),
c("P-value", formatC(abbreviated_4, format = "e", digits = 2)))
tabletext
png("forestplot.png", width = 2400, height = 980)
forestplot(labeltext = tabletext,
mean = c(NA, abbreviated_1),
lower = c(NA, abbreviated_2),
upper = c(NA, abbreviated_3),
ci.vertices = T,
is.summary = c(TRUE, rep(FALSE, 7)),
fn.ci_norm = fpDrawCircleCI,
boxsize = 0.3,
txt_gp = fpTxtGp(ticks = gpar(cex = 3.6), xlab = gpar(cex = 3), label = gpar(cex =4)),
xlab = " ",
lwd.ci = 6,
xlog = TRUE,
#xticks = c(0, 1, 2, 3, 4, 5, 6),
hrzl_lines = gpar(col = "#444444"),
linesheight = "lines",
new_page = FALSE,
col = fpColors(box = c("black"), lines = "black"))
dev.off()
######### RELATIVE RISK June 18 TN #####
model = glm(mask ~ age + avg_zscore_price_index + gender + case_rate, data = merged, family = binomial)
# ran into issue of starting value with age, so I used the solution from https://stackoverflow.com/questions/31342637/error-please-supply-starting-values
set.seed(123)
coefini = coef(glm(mask ~ gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log")))
modelRR = glm(mask ~ age + gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log"), start=c(coefini,0,0,0))
summary(modelRR)
exp(coef(modelRR))
modelRR = glm(mask ~ age + gender + case_rate + avg_zscore_price_index, data = merged, family = poisson)#, start=c(coefini,0,0,0))
exp(coef(modelRR))
model = modelRR
RR = data.frame(exp(cbind("Relative risk" = coef(model), confint.default(model, level = 0.95))), pvalue = summary(model)$coefficients[,4], check.names = F)
RR
RR = RR[c("agey","agea","agee","avg_zscore_price_index","genderFemale","case_rate"),]
abbreviated_1 = RR[,1]
abbreviated_2 = RR[,2]
abbreviated_3 = RR[,3]
abbreviated_4 = RR[,4]
tabletext=cbind(
c(" ", "Young adult", "Adult", "Older adult", "High price index", "Female gender", "High case prevalence"),
c("aRR", formatC(abbreviated_1, digits = 2, drop0trailing = FALSE, format = "f")),
c("Lower CI", formatC(abbreviated_2, digits = 2, format = "f", drop0trailing = FALSE)),
c("Upper CI", formatC(abbreviated_3, digits = 2, format = "f", drop0trailing = FALSE)),
c("P-value", formatC(abbreviated_4, format = "e", digits = 2)))
tabletext
<<<<<<< Updated upstream
modelRR = glm(mask ~ age + gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log"), start=c(coefini,1,1,1))
modelRR = glm(mask ~ age + gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log"), start=c(coefini,0,0,0))
warnings()
coefini = coef(glm(mask ~ gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log")))
modelRR = glm(mask ~ age + gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log"), start=c(coefini,0,0,0))
summary(modelRR)
modelRR = glm(mask ~ gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log"), start=c(coefini,0,0,0))
modelRR = glm(mask ~ gender + case_rate + avg_zscore_price_index, data = merged, family = binomial(link="log"), start=c(coefini))
summary(modelRR)
exp(coef(modelRR))
model = modelRR
RR = data.frame(exp(cbind("Relative risk" = coef(model), confint.default(model, level = 0.95))), pvalue = summary(model)$coefficients[,4], check.names = F)
RR
>>>>>>> Stashed changes
=======
png("forestplot.png", width = 2400, height = 980)
forestplot(labeltext = tabletext,
mean = c(NA, abbreviated_1),
lower = c(NA, abbreviated_2),
upper = c(NA, abbreviated_3),
ci.vertices = T,
is.summary = c(TRUE, rep(FALSE, 7)),
fn.ci_norm = fpDrawCircleCI,
boxsize = 0.3,
txt_gp = fpTxtGp(ticks = gpar(cex = 3.6), xlab = gpar(cex = 3), label = gpar(cex =4)),
xlab = " ",
lwd.ci = 6,
xlog = TRUE,
#xticks = c(0, 1, 2, 3, 4, 5, 6),
hrzl_lines = gpar(col = "#444444"),
linesheight = "lines",
new_page = FALSE,
col = fpColors(box = c("black"), lines = "black"))
dev.off()
library(ggmap)
library(maps)
library(mapdata)
#pull state boundaries
states= map_data("state")
wisconsin=subset(states,region =='wisconsin')
#add in county lines
#column headers are: long,lat,group,order,region,subregion
usa_counties=map_data('county')
counties=subset(usa_counties,region=='wisconsin')
counties$subregion = replace(counties$subregion, counties$subregion=="st croix", "st_croix")
counties$subregion = replace(counties$subregion, counties$subregion=="fond du lac", "fond_du_lac")
View(merged)
# SECTION 3: Logistic Regression and Odds Ratios ####
merged = read.csv("InputData/meta_merged_observed.csv",row.names = 1, check.names = F, stringsAsFactors = 1)
merged$gender = as.factor(recode(merged$gender, `0` = "Male", `1` = "Female"))
merged$gender = fct_relevel(merged$gender, ref = "Male")
#merged$age = recode(merged$age, a = "30-59", c = "<18", y = "18-29", e = "60+")
#merged$age = fct_relevel(merged$age, levels = c("<18", "18-29", "30-59", "60+"))
merged$age = fct_relevel(merged$age, levels = c("c", "y", "a", "e"))
merged$age = droplevels(merged$age)
# Setting threshold for high case rate vs low case rate
threshold = 800
merged$age = droplevels(merged$age)
test = merged
#Grahing potential effect of interaction term
merged_top5_marker <- merged %>%
mutate(Top5 = case_when(
county %in% c("dane", "brown", "racine", "outagamie", "winnebago", "milwaukee", "kenosha") ~ "Top5",
TRUE ~ "Not top 5"))
merged_top5_marker %>%
group_by(county) %>%
summarize(percentage_wearing_mask = sum(mask)/n()*100) %>%
right_join(merged_top5_marker, by = "county") %>%
ggplot(aes(x = case_rate_two_weeks_prior, y = percentage_wearing_mask, color = pop_total, label = county)) +
facet_wrap(~Top5) +
geom_point() +
geom_smooth(method = lm, se = FALSE) +
scale_color_gradient(low = "grey", high = "blue", na.value = NA) +
geom_text(aes(label=county))
ggsave("./interaction_term_caserate_pop_total.png")
ggsave("./interaction_term_caserate_pop_total.png")
summary(model)
install.packages("glmulti")
library(glmulti)
test_model = glmulti(mask ~ age + avg_zscore_price_index + gender + case_rate + pop_total, data = merged,
level = 1,               # No interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 5,         # Keep 5 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
test_model
glmulti.logistic.out@formulas
test_model@formulas
test_model
test_model[[1]]
test_model@objects[[1]]
test_model@objects[[2]]
test_model@formulas
test_model = glmulti(mask ~ age + avg_zscore_price_index + gender + case_rate + pop_total, data = merged,
level = 2,               # No interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 5,         # Keep 5 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
test_model@formulas
test_model
merged_test
merged_test = merged
View(merged_test)
colnames(merged_test)
merged_test = merged[,c("location","gloves","mask","homeade","gender","age","time","temp","weather",
"no_cases","case_rate","avg_zscore_price_index","median_zscore_price_index","pop_density","pop_total","case_rate_june19","case_rate_two_weeks_prior",
"age_two_bins")]
View(merged_test)
test_model = glmulti(mask ~ age + avg_zscore_price_index + gender + case_rate + pop_total, data = merged_test,
level = 1,               # No interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 5,         # Keep 5 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
test_model
test_model = glmulti(mask ~., data = merged_test,
level = 1,               # No interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 5,         # Keep 5 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
test_model
merged_test = merged[,c("county","location","gloves","mask","homeade","gender","age","weather",
"no_cases","case_rate","avg_zscore_price_index","pop_density","pop_total")]
View(merged_test)
test_model = glmulti(mask ~., data = merged_test,
level = 1,               # No interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 5,         # Keep 5 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
test_model
test_model@objects[[1]]
merged_test = merged[,c("location","gloves","mask","homeade","gender","age","weather",
"no_cases","case_rate","avg_zscore_price_index","pop_density","pop_total")]
View(merged_test)
test_model = glmulti(mask ~., data = merged_test,
level = 1,               # No interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 5,         # Keep 5 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
test_model
merged_test = merged[,c("location","gloves","mask","homeade","gender","age","time",
"no_cases","case_rate","avg_zscore_price_index","pop_density","pop_total")]
merged_test = merged[,c("location","mask","gender","age","time",
"no_cases","case_rate","avg_zscore_price_index","pop_density","pop_total")]
test_model = glmulti(mask ~., data = merged_test,
level = 1,               # No interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 5,         # Keep 5 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
test_model@objects[[1]]
merged$time
hist(merged$time)
plot(density(merged$time))
>>>>>>> Stashed changes
